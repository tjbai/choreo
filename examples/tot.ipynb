{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ca7760-6bfc-438b-b65a-5fb4f4ba9383",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfb45fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama import Workflow, Llama\n",
    "\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"29500\"\n",
    "\n",
    "workflow = Workflow.build(\n",
    "    ckpt_dir='/scratch4/jeisner1/tjbai/llama_8b',\n",
    "    tokenizer_path='/scratch4/jeisner1/tjbai/llama_8b/tokenizer.model',\n",
    "    max_seq_len=512*16,\n",
    "    max_batch_size=4,\n",
    "    model_parallel_size=1\n",
    ")\n",
    "\n",
    "llama = Llama(workflow.model, workflow.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc9ad4f-b984-449a-93ed-864c0a282904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "cot_prompt = '''\n",
    "You are a creative problem solver with deep expertise in competition mathematics.\n",
    "Your goal is to find a clean and insightful approach to solving the provided problem.\n",
    "\n",
    "Before proceeding, first plan out your approach. Here are some tips:\n",
    "- Break down the reasoning into clear, atomic steps\n",
    "- Explicitly state any assumptions or key insights\n",
    "\n",
    "Keep your proposal high-level and concise. You do not need to solve the entire problem.\n",
    "\n",
    "Format your response as:\n",
    "INSIGHT: (1 sentence summary)\n",
    "POTENTIAL CHALLENGES: (2-3 sentences)\n",
    "APPROACH:\n",
    "1. ...\n",
    "2. ...\n",
    "'''\n",
    "\n",
    "finish_prompt = '''\n",
    "You are a creative problem solver with deep expertise in competition mathematics.\n",
    "Your goal is to solve the provided problem. You may find it helpful to utilize the previously generated proposal.\n",
    "Keep your solution relatively concise, leaning mostly on previously developed ideas.\n",
    "\n",
    "Format your response as:\n",
    "ANSWER: (2-3 sentence summary of solution and final answer)\n",
    "'''\n",
    "\n",
    "def format_vote_prompt(n):\n",
    "    return f'''\n",
    "    You are a rigorous mathematical evaluator with deep expertise in competition mathematics.\n",
    "    You will be shown several different solution strategies for a math problem. Your task is to analyze each and select the most promising one to pursue.\n",
    "\n",
    "    It may help to evaluate on the following principles:\n",
    "    - Mathematical soundness: Are all the steps logicall valid?\n",
    "    - Tractability: Is the proposed solution computationally complex? Are there potential dead ends?\n",
    "    - Elegance: Does this approach effectively leverage key problem structure?\n",
    "\n",
    "    Vote on the best proposal and justify your choice. You will see {n} proposals, so respond with the proposal 1 through {n}.\n",
    "    Do not attempt to solve the problem. You only need to evaluate each proposal and select the best option.\n",
    "\n",
    "    Format your response as:\n",
    "    BEST CHOICE: (index of best solution)\n",
    "    RATIONALE: (1 sentence justification)\n",
    "    '''\n",
    "\n",
    "def format_problem(problem):\n",
    "    return f'Here is the provided problem:\\n{problem}'\n",
    "\n",
    "def parse_choice(text):\n",
    "    match = re.search(r'BEST CHOICE:\\s*(\\d+)', text)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "def solve(problem, n=5):\n",
    "    workflow.reset()\n",
    "\n",
    "    cot, vote, finish = workflow.insert([\n",
    "        {\n",
    "            'message': {'role': 'system', 'content': cot_prompt},\n",
    "            'parent_ids': []\n",
    "        },\n",
    "        {\n",
    "            'message': {'role': 'system', 'content': format_vote_prompt(n)},\n",
    "            'parent_ids': []\n",
    "        },\n",
    "        {\n",
    "            'message': {'role': 'system', 'content': finish_prompt},\n",
    "            'parent_ids': []\n",
    "        },\n",
    "    ])\n",
    "\n",
    "    # seems to matter that these are separate\n",
    "    cot_user, vote_user, finish_user = workflow.insert([\n",
    "        {\n",
    "            'message': {'role': 'user', 'content': format_problem(problem)},\n",
    "            'parent_ids': [cot['id']]\n",
    "        },\n",
    "        {\n",
    "            'message': {'role': 'user', 'content': format_problem(problem)},\n",
    "            'parent_ids': [vote['id']]\n",
    "        },\n",
    "        {\n",
    "            'message': {'role': 'user', 'content': format_problem(problem)},\n",
    "            'parent_ids': [finish['id']]\n",
    "        },\n",
    "    ])\n",
    "    \n",
    "    proposal_tokens, proposal_nodes = workflow.step(\n",
    "        [\n",
    "            {\n",
    "                'expects': ('assistant', f'solution {i+1}'),\n",
    "                'parent_ids': [cot['id'], cot_user['id']]\n",
    "            }\n",
    "            for i in range(n)\n",
    "        ],\n",
    "        compact=False,\n",
    "        prefill=True,\n",
    "        max_gen_len=1024,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        seed=42,\n",
    "    )\n",
    "\n",
    "    vote_tokens, vote_nodes = workflow.step(\n",
    "        [\n",
    "            {\n",
    "                'expects': ('assistant', None),\n",
    "                'parent_ids': [vote['id'], vote_user['id']] + [p['id'] for p in proposal_nodes]\n",
    "            }\n",
    "            for _ in range(5)\n",
    "        ],\n",
    "        compact=False,\n",
    "        prefill=True,\n",
    "        max_gen_len=256,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        seed=42,\n",
    "    )\n",
    "    \n",
    "    res = None\n",
    "    votes = [\n",
    "        choice for resp in vote_tokens if \n",
    "        (choice := parse_choice(workflow.tokenizer.decode(resp))) is not None\n",
    "    ]\n",
    "    \n",
    "    if len(votes) > 0:\n",
    "        best = Counter(votes).most_common(1)[0][0]\n",
    "        [res], _ = workflow.step(\n",
    "            [\n",
    "                {\n",
    "                    'expects': ('assistant', None),\n",
    "                    'parent_ids': [finish['id'], finish_user['id']] + [proposal_nodes[best-1]['id']]\n",
    "                }\n",
    "            ],\n",
    "            compact=False,\n",
    "            prefill=True,\n",
    "            max_gen_len=256,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            seed=42,\n",
    "        )\n",
    "    \n",
    "    return proposal_tokens, vote_tokens, res, votes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama3",
   "language": "python",
   "name": "llama3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
