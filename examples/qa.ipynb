{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b8d4292-6031-45b3-a44c-5e0988dae8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e22b1fc-910a-41b0-9d4a-3db0d1b606e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> initializing model parallel with size 1\n",
      "> initializing ddp with size 1\n",
      "> initializing pipeline with size 1\n",
      "Loaded in 34.17 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from llama import Workflow, Llama\n",
    "\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"29502\"\n",
    "\n",
    "workflow = Workflow.build(\n",
    "    ckpt_dir='/scratch4/jeisner1/tjbai/llama_8b',\n",
    "    tokenizer_path='/scratch4/jeisner1/tjbai/llama_8b/tokenizer.model',\n",
    "    max_seq_len=8192,\n",
    "    max_batch_size=8,\n",
    "    model_parallel_size=1,\n",
    "    max_nodes=100,\n",
    ")\n",
    "\n",
    "llama = Llama(workflow.model, workflow.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dc5b083-f642-46e7-a313-0de122cb94dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/home/tbai4/llama3/data/triviaqa/unfiltered-web-train.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "819446c2-c55b-47fe-862b-8bfbca3bda25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###\n",
      "Who was President when the first Peanuts cartoon was published?\n",
      "Harry Truman\n",
      "###\n",
      "Which American-born Sinclair won the Nobel Prize for Literature in 1930?\n",
      "Sinclair Lewis\n",
      "###\n",
      "Where in England was Dame Judi Dench born?\n",
      "York\n",
      "###\n",
      "William Christensen of Madison, New Jersey, has claimed to have the world's biggest collection of what?\n",
      "Beer Cans\n",
      "###\n",
      "In which decade did Billboard magazine first publish and American hit chart?\n",
      "30s\n",
      "###\n",
      "Where was horse racing's Breeders' Cup held in 1988?\n",
      "Churchill Downs, Louisville, Kentucky\n",
      "###\n",
      "From which country did Angola achieve independence in 1975?\n",
      "Portugal\n",
      "###\n",
      "Which city does David Soul come from?\n",
      "Chicago\n",
      "###\n",
      "Who won Super Bowl XX?\n",
      "Chicago Bears\n",
      "###\n",
      "Which was the first European country to abolish capital punishment?\n",
      "Norway\n"
     ]
    }
   ],
   "source": [
    "problems = data['Data']\n",
    "\n",
    "for i, problem in enumerate(problems):\n",
    "    if i == 10:\n",
    "        break\n",
    "    print('###')\n",
    "    print(problem['Question'])\n",
    "    print(problem['Answer']['Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80ffedbf-924d-4b04-a118-fbf4d35961d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter as get\n",
    "\n",
    "def ask_sequential(workflow, subset):\n",
    "    workflow.reset()\n",
    "    \n",
    "    [prompt] = workflow.insert([\n",
    "        {\n",
    "            'messages': (\n",
    "                [{'role': 'system', 'content': 'Answer ALL of the user\\'s questions. Answer with an numbered list. Do not include extraneous text.'}] +\n",
    "                [{'role': 'user', 'content': f'Question {i+1}: {p['Question']}'} for i, p in enumerate(subset)]\n",
    "            ),\n",
    "            'parent_ids': []\n",
    "        }\n",
    "    ])\n",
    "    \n",
    "    [response] = get('tokens')(workflow.step(\n",
    "        tasks=[{\n",
    "            'header': ('assistant', None),\n",
    "            'prefill': '',\n",
    "            'parent_ids': [prompt['id']],\n",
    "        }]\n",
    "    ))\n",
    "    \n",
    "    return workflow.tokenizer.decode(response)\n",
    "\n",
    "def ask_parallel(workflow, subset, annotate=False, compact=False):\n",
    "    workflow.reset()\n",
    "    \n",
    "    [prompt] = workflow.insert([\n",
    "        {\n",
    "            'messages': [{'role': 'system', 'content': 'Answer ALL of the user\\'s questions. Answer with an numbered list. Do not include extraneous text.'}],\n",
    "            'parent_ids': []\n",
    "        }\n",
    "    ])\n",
    "\n",
    "    questions = workflow.insert([\n",
    "        {\n",
    "            'messages': [{'role': 'user', 'content': f'{f'Question {i+1}: ' if annotate else ''}{p['Question']}'}],\n",
    "            'parent_ids': [prompt['id']],\n",
    "        }\n",
    "        for i, p in enumerate(subset)\n",
    "    ])\n",
    "    \n",
    "    [response] = get('tokens')(workflow.step(\n",
    "        tasks=[{\n",
    "            'header': ('assistant', None),\n",
    "            'prefill': '',\n",
    "            'parent_ids': [prompt['id']] + [q['id'] for q in questions],\n",
    "        }],\n",
    "        compact=compact\n",
    "    ))\n",
    "    \n",
    "    return workflow.tokenizer.decode(response)\n",
    "\n",
    "def parse_items(text):\n",
    "    lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
    "    items = [line.split('. ', 1)[1] if '. ' in line else line for line in lines]\n",
    "    return items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f799241-7ff4-4cfd-9ea1-fcc6d9cefe8c",
   "metadata": {},
   "source": [
    "## N=2, sequential (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cea0e884-4cc3-4dba-bdf6-b3bb39b55902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:23<00:00,  1.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11292"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "output = []\n",
    "for seed in tqdm(range(30)):\n",
    "    random.seed(seed)\n",
    "    output.append(f\"\\n## Trial {seed}\\n\")\n",
    "    subset = random.sample(problems, k=2)\n",
    "    answer = ask_sequential(workflow, subset)\n",
    "\n",
    "    for i, (s, answer) in enumerate(zip(subset, parse_items(answer))):\n",
    "        output.extend([\n",
    "            f\"### Question {i+1}\\n\",\n",
    "            f\"**Question:** {s['Question']}\\n\", \n",
    "            f\"**Ground Truth:** {s['Answer']['Value']}\\n\",\n",
    "            f\"**Generated:** {answer}\\n\"\n",
    "        ])\n",
    "        if i < len(subset) - 1:\n",
    "            output.append(\"\\n---\\n\")\n",
    "\n",
    "Path('/home/tbai4/llama3/dumps/sequential_n2.md').write_text('\\n'.join(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cd779e-00da-46a1-a752-1dd03f0eebaa",
   "metadata": {},
   "source": [
    "## N=2, Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b767bfe-a467-4893-b842-2235de1971ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "annotate=False, compact=False: 100%|██████████| 30/30 [00:17<00:00,  1.74it/s]\n",
      "annotate=True, compact=False: 100%|██████████| 30/30 [00:17<00:00,  1.75it/s]\n",
      "annotate=False, compact=True: 100%|██████████| 30/30 [00:16<00:00,  1.81it/s]\n",
      "annotate=True, compact=True: 100%|██████████| 30/30 [00:18<00:00,  1.64it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "configs = [\n",
    "   ('parallel_base_n2.md', False, False),\n",
    "   ('parallel_annotated_n2.md', True, False), \n",
    "   ('parallel_linearized_n2.md', False, True),\n",
    "   ('parallel_annotated_linearized_n2.md', True, True)\n",
    "]\n",
    "\n",
    "for filename, annotate, compact in configs:\n",
    "    output = []\n",
    "    for seed in tqdm(range(30), desc=f\"annotate={annotate}, compact={compact}\"):\n",
    "        random.seed(seed)\n",
    "        output.append(f\"\\n## Trial {seed}\\n\")\n",
    "        subset = random.sample(problems, k=2)\n",
    "        answer = ask_parallel(workflow, subset, annotate=annotate, compact=compact)\n",
    "\n",
    "        for i, (s, answer) in enumerate(zip(subset, parse_items(answer))):\n",
    "            output.extend([\n",
    "                f\"### Question {i+1}\\n\",\n",
    "                f\"**Question:** {s['Question']}\\n\", \n",
    "                f\"**Ground Truth:** {s['Answer']['Value']}\\n\",\n",
    "                f\"**Generated:** {answer}\\n\"\n",
    "            ])\n",
    "            \n",
    "        if i < len(subset) - 1:\n",
    "            output.append(\"\\n---\\n\")\n",
    "\n",
    "    Path(f'/home/tbai4/llama3/dumps/triviaqa/{filename}').write_text('\\n'.join(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0697b331-0abf-4773-9786-c06d14d406fd",
   "metadata": {},
   "source": [
    "## exploratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32a72e2f-ea9c-40a0-ba36-b9ef44a40a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Chicago\n",
      "2. Richard Nixon\n",
      "3. Portugal\n",
      "4. Chicago Bears\n"
     ]
    }
   ],
   "source": [
    "res = llama.chat_completion(\n",
    "    dialogs=[[\n",
    "        {'role': 'system', 'content': 'Answer ALL of the user\\'s questions. Answer with an numbered list. Do not include extraneous text.'},\n",
    "        {'role': 'user', 'content': 'Which city does David Soul come from?'},\n",
    "        {'role': 'user', 'content': 'Who was President when the first Peanuts cartoon was published?'},\n",
    "        {'role': 'user', 'content': 'From which country did Angola achieve independence in 1975?'},\n",
    "        {'role': 'user', 'content': 'Who won Super Bowl XX?'},\n",
    "    ]]\n",
    ")\n",
    "\n",
    "print(res[0]['generation']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "68f66bd6-c4c5-4c51-a871-0a4281ef26c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Chicago\n",
      "2. Richard Nixon\n",
      "3. Portugal\n",
      "4. Chicago Bears\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter as get\n",
    "\n",
    "messages = [\n",
    "    {'role': 'system', 'content': 'Answer ALL of the user\\'s questions. Answer with an numbered list. Do not include extraneous text.'},\n",
    "    {'role': 'user', 'content': 'Which city does David Soul come from?'},\n",
    "    {'role': 'user', 'content': 'Who was President when the first Peanuts cartoon was published?'},\n",
    "    {'role': 'user', 'content': 'From which country did Angola achieve independence in 1975?'},\n",
    "    {'role': 'user', 'content': 'Who won Super Bowl XX?'}\n",
    "]\n",
    "\n",
    "[prompt] = workflow.insert([{'messages': messages, 'parent_ids': []}])\n",
    "\n",
    "[response] = get('tokens')(workflow.step(\n",
    "    [{\n",
    "        'header': ('assistant', None),\n",
    "        'prefill': '',\n",
    "        'parent_ids': [prompt['id']]\n",
    "    }]\n",
    "))\n",
    "\n",
    "print(workflow.tokenizer.decode(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2ec22d1b-76cd-4909-aa21-2adcaa030b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Gerald Ford\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter as get\n",
    "\n",
    "workflow.reset()\n",
    "\n",
    "[prompt] = workflow.insert([\n",
    "    {\n",
    "        'messages': [{'role': 'system', 'content': 'Answer ALL of the user\\'s questions. Answer with an numbered list. Do not include extraneous text.'}],\n",
    "        'parent_ids': []\n",
    "    }\n",
    "])\n",
    "\n",
    "questions = workflow.insert([\n",
    "        {\n",
    "            'messages': [{'role': 'user', 'content': 'Question 1: Which city does David Soul come from?'}],\n",
    "            'parent_ids': [prompt['id']],\n",
    "        },\n",
    "        {\n",
    "            'messages': [{'role': 'user', 'content': 'Question 4: From which country did Angola achieve independence in 1975?'},],\n",
    "            'parent_ids': [prompt['id']],\n",
    "        },\n",
    "        {\n",
    "            'messages': [{'role': 'user', 'content': 'Question 3: Who won Super Bowl XX?'},],\n",
    "            'parent_ids': [prompt['id']],\n",
    "        },\n",
    "        {\n",
    "            'messages': [{'role': 'user', 'content': 'Question 2: Who was President when the first Peanuts cartoon was published?'},],\n",
    "            'parent_ids': [prompt['id']],\n",
    "        },\n",
    "])\n",
    "\n",
    "[response] = get('tokens')(workflow.step(\n",
    "    tasks=[{\n",
    "        'header': ('assistant', None),\n",
    "        'prefill': '',\n",
    "        'parent_ids': [prompt['id']] + [q['id'] for q in questions],\n",
    "    }],\n",
    "    compact=True\n",
    "))\n",
    "\n",
    "print(workflow.tokenizer.decode(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9bb9f883-5e87-45b6-a48d-9e9da8122afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Chicago\n",
      "2. United States\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter as get\n",
    "\n",
    "workflow.reset()\n",
    "\n",
    "[prompt] = workflow.insert([\n",
    "    {\n",
    "        'messages': [{'role': 'system', 'content': 'Answer ALL of the user\\'s questions. Answer with an numbered list. Do not include extraneous text.'}],\n",
    "        'parent_ids': []\n",
    "    }\n",
    "])\n",
    "\n",
    "questions = workflow.insert([\n",
    "        {\n",
    "            'messages': [\n",
    "                {'role': 'user', 'content': 'Which city does David Soul come from?'},\n",
    "                {'role': 'user', 'content': 'From which country did Angola achieve independence in 1975?'},\n",
    "            ],\n",
    "            'parent_ids': [prompt['id']],\n",
    "        },\n",
    "        {\n",
    "            'messages': [\n",
    "                {'role': 'user', 'content': 'Who won Super Bowl XX?'},\n",
    "                {'role': 'user', 'content': 'Who was President when the first Peanuts cartoon was published?'},\n",
    "            ],\n",
    "            'parent_ids': [prompt['id']],\n",
    "        },\n",
    "])\n",
    "\n",
    "[response] = get('tokens')(workflow.step(\n",
    "    tasks=[{\n",
    "        'header': ('assistant', None),\n",
    "        'prefill': '',\n",
    "        'parent_ids': [prompt['id']] + [q['id'] for q in questions],\n",
    "    }],\n",
    "))\n",
    "\n",
    "print(workflow.tokenizer.decode(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama3",
   "language": "python",
   "name": "llama3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
