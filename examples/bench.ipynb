{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6ca7760-6bfc-438b-b65a-5fb4f4ba9383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tbai4/llama3/llama\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tbai4/llama3/.venv/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%cd llama3/llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dfb45fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> initializing model parallel with size 1\n",
      "> initializing ddp with size 1\n",
      "> initializing pipeline with size 1\n",
      "Loaded in 16.92 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from llama import Workflow, Llama\n",
    "\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"29500\"\n",
    "\n",
    "workflow = Workflow.build(\n",
    "    ckpt_dir='/scratch4/jeisner1/tjbai/llama_8b',\n",
    "    tokenizer_path='/scratch4/jeisner1/tjbai/llama_8b/tokenizer.model',\n",
    "    max_seq_len=512*16,\n",
    "    max_batch_size=1,\n",
    "    model_parallel_size=1,\n",
    "    max_nodes=100,\n",
    "    max_parents=10\n",
    ")\n",
    "\n",
    "llama = Llama(workflow.model, workflow.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcdfd09c-5355-4517-a34c-c72b7126c64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example #1\n",
      "To solve the problem, we can count the number of ways to assign a role to each person. \n",
      "\n",
      "First, let's choose any of the 4\n",
      "\n",
      "example #2\n",
      "However, thinking about it, if we fix one element, the rest can be arranged in a circular manner, but since there are 9 numbers left to\n",
      "\n",
      "example #3\n",
      "However, we don't want to divide by the number of rotations. We can first fix one number as the first.\n",
      "\n",
      "example #4\n",
      "We know that there are (n-1)! ways to arrange the remaining elements in a circular permutation. In this case, n is the total number of\n",
      "\n"
     ]
    }
   ],
   "source": [
    "workflow.reset()\n",
    "\n",
    "[generate_prompt, evaluate_prompt] = workflow.insert([\n",
    "    {\n",
    "        'messages': [\n",
    "            {'role': 'system', 'content': 'You will be shown a math problem. Provide a high-level summary of how to solve the problem.'},\n",
    "            {'role': 'user', 'content': 'Here is the problem: How many ways can you sit 10 different people around a round table?'}\n",
    "        ],\n",
    "        'parent_ids': [],\n",
    "    },\n",
    "    {\n",
    "        'messages': [\n",
    "            {'role': 'system', 'content': 'Given a math problem and numerous proposed solutions, echo back to the user all of the solutions.'},\n",
    "        ],\n",
    "        'parent_ids': []\n",
    "    }\n",
    "])\n",
    "\n",
    "resp1, resp2 = workflow.insert([\n",
    "    {\n",
    "        'messages': [{'role': 'assistant', 'content': 'We can possibly use binomial coefficients to solve this problem via combinations.'}],\n",
    "        'parent_ids': [generate_prompt['id']],\n",
    "    },\n",
    "    {\n",
    "        'messages': [{'role': 'assistant', 'content': 'We can consider all 10 permutations and cancel out the rotational symmetry.'}],\n",
    "        'parent_ids': [evaluate_prompt['id']],\n",
    "    },\n",
    "])\n",
    "\n",
    "tokens, cached = workflow.step(\n",
    "    tasks=[\n",
    "        {\n",
    "            'header': ('assistant', None),\n",
    "            'parent_ids': [evaluate_prompt['id'], resp2['id'], resp1['id']],\n",
    "        }\n",
    "        for _ in range(4)\n",
    "    ],\n",
    "    compact=False,\n",
    "    max_gen_len=32,\n",
    "    temperature=1.0,\n",
    "    top_p=1.0,\n",
    "    seed=1,\n",
    "    stateless=False\n",
    ")\n",
    "\n",
    "for i, output in enumerate(tokens):\n",
    "    print(f'example #{i+1}')\n",
    "    print(workflow.tokenizer.decode(output))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27c98d97-1cb0-4c50-aa90-21ddb54340e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama.benchmark import benchmark_workflow, solve_workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d0cec4e-3e3d-4d1b-930d-c1fd5a244f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def load_math_problems(root_dir, split, problem_types):\n",
    "    problems = []\n",
    "    root = Path(root_dir) / split\n",
    "    \n",
    "    for problem_type in problem_types:\n",
    "        type_dir = root / problem_type\n",
    "        if not type_dir.exists():\n",
    "            continue\n",
    "        for prob_file in type_dir.glob(\"*.json\"):\n",
    "            with open(prob_file) as f:\n",
    "                problem = json.load(f)\n",
    "                problems.append(problem)\n",
    "    \n",
    "    return problems\n",
    "\n",
    "problems = load_math_problems('../../MATH', 'train', ['counting_and_probability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac287dcb-08f5-41f1-8213-61a98a50a612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1\n",
      "Finished in 11.961941386805847\n",
      "Memory usage: 1.38 GB\n",
      "Trial 2\n",
      "Finished in 14.78994380007498\n",
      "Memory usage: 1.70 GB\n",
      "Trial 3\n",
      "Finished in 23.786685358034447\n",
      "Memory usage: 3.61 GB\n",
      "\n",
      "Profile for case 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m case \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mworkflow\u001b[39m\u001b[38;5;124m'\u001b[39m: workflow,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproblem\u001b[39m\u001b[38;5;124m'\u001b[39m: problems[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproblem\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbranching_factor\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvoters\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      6\u001b[0m }\n\u001b[0;32m----> 8\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mbenchmark_workflow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkflow_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolve_workflow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_cases\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcase\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprofile/tot\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/llama3/llama/benchmark/benchmark.py:56\u001b[0m, in \u001b[0;36mbenchmark_workflow\u001b[0;34m(workflow_fn, test_cases, n_trials, output_dir)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mProfile for case \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     54\u001b[0m     prof\u001b[38;5;241m.\u001b[39mexport_chrome_trace(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/trace_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m     \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m({\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmean(times),\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mstd(times),\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimes\u001b[39m\u001b[38;5;124m'\u001b[39m: times,\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprofile\u001b[39m\u001b[38;5;124m'\u001b[39m: prof,\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m'\u001b[39m: outputs\n\u001b[1;32m     62\u001b[0m     })\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "case = {\n",
    "    'workflow': workflow,\n",
    "    'problem': problems[1]['problem'],\n",
    "    'branching_factor': 2,\n",
    "    'voters': 5\n",
    "}\n",
    "\n",
    "results = benchmark_workflow(\n",
    "    workflow_fn=solve_workflow,\n",
    "    test_cases=[case],\n",
    "    n_trials=3,\n",
    "    output_dir='profile/tot'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba255a6-dc00-475d-8e7a-4a0f4ba1bccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ee5fa5-ade9-48f3-a177-25319fdfee3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama3",
   "language": "python",
   "name": "llama3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
