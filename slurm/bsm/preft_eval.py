import os
import json
import numpy as np
from tqdm import tqdm
from pathlib import Path

from llama import Workflow
from llama.util import find_free_port
from llama.workflows.bsm import load_concepts
from llama.workflows.bsm import bsm_baseline, bsm_cached

os.environ["RANK"] = "0"
os.environ["WORLD_SIZE"] = "1"
os.environ["MASTER_ADDR"] = "localhost"
os.environ["MASTER_PORT"] = str(find_free_port())

workflow = Workflow.build(
    ckpt_dir='/scratch4/jeisner1/tjbai/llama_8b',
    tokenizer_path='/scratch4/jeisner1/tjbai/llama_8b/tokenizer.model',
    max_seq_len=8192,
    max_batch_size=8,
    model_parallel_size=1,
    max_nodes=100,
)

concepts_list = load_concepts(
    data_path='/home/tbai4/llama3/data/commongen/commongen.jsonl',
    split='dev',
)

output_dir = Path('dumps/bsm')
output_dir.mkdir(parents=True, exist_ok=True)

concepts = []

baseline_stories = []
baseline_all_concepts = []
baseline_coverage = []
baseline_group1_coverage = []  # group 1 coverage
baseline_group2_coverage = []  # group 2 coverage

cached_stories = []
cached_all_concepts = []
cached_coverage = []
cached_group1_coverage = []  # group 1 coverage
cached_group2_coverage = []  # group 2 coverage

cached_compact_stories = []
cached_compact_all_concepts = []
cached_compact_coverage = []
cached_compact_group1_coverage = []  # group 1 coverage
cached_compact_group2_coverage = []  # group 2 coverage

for idx, concept_set in enumerate(tqdm(concepts_list, desc="Evaluating")):
    concepts.append(concept_set)

    # bsm baseline
    workflow.reset()
    try:
        outputs = bsm_baseline(workflow=workflow, concepts=concept_set)
        if outputs is None:
            raise ValueError("Method returned None")

        story = workflow.tokenizer.decode(outputs['merge_tokens'][0])

        # extract the concept groups generated by the LLM
        group1_concepts = outputs['concept_groups'][0]
        group2_concepts = outputs['concept_groups'][1]

        # overall concept coverage
        concept_present = [concept.lower() in story.lower() for concept in concept_set]
        all_present = all(concept_present)
        coverage = sum(concept_present) / len(concept_set)

        # group-specific coverage
        group1_present = [concept.lower() in story.lower() for concept in group1_concepts]
        group1_coverage = sum(group1_present) / len(group1_concepts)

        group2_present = [concept.lower() in story.lower() for concept in group2_concepts]
        group2_coverage = sum(group2_present) / len(group2_concepts)

        baseline_stories.append(story)
        baseline_all_concepts.append(all_present)
        baseline_coverage.append(coverage)
        baseline_group1_coverage.append(group1_coverage)
        baseline_group2_coverage.append(group2_coverage)

    except Exception as e:
        print(f"Error in bsm_baseline: {e}")
        baseline_stories.append(f"ERROR: {str(e)}")
        baseline_all_concepts.append(False)
        baseline_coverage.append(0.0)
        baseline_group1_coverage.append(0.0)
        baseline_group2_coverage.append(0.0)

    # bsm cached
    workflow.reset()
    try:
        outputs = bsm_cached(workflow=workflow, concepts=concept_set)
        if outputs is None:
            raise ValueError("Method returned None")

        story = workflow.tokenizer.decode(outputs['merge_tokens'][0])

        # extract the concept groups generated by the LLM
        group1_concepts = outputs['concept_groups'][0]
        group2_concepts = outputs['concept_groups'][1]

        # overall concept coverage
        concept_present = [concept.lower() in story.lower() for concept in concept_set]
        all_present = all(concept_present)
        coverage = sum(concept_present) / len(concept_set)

        # group-specific coverage
        group1_present = [concept.lower() in story.lower() for concept in group1_concepts]
        group1_coverage = sum(group1_present) / len(group1_concepts)

        group2_present = [concept.lower() in story.lower() for concept in group2_concepts]
        group2_coverage = sum(group2_present) / len(group2_concepts)

        cached_stories.append(story)
        cached_all_concepts.append(all_present)
        cached_coverage.append(coverage)
        cached_group1_coverage.append(group1_coverage)
        cached_group2_coverage.append(group2_coverage)

    except Exception as e:
        print(f"Error in bsm_cached: {e}")
        cached_stories.append(f"ERROR: {str(e)}")
        cached_all_concepts.append(False)
        cached_coverage.append(0.0)
        cached_group1_coverage.append(0.0)
        cached_group2_coverage.append(0.0)

    # bsm cached compact
    workflow.reset()
    try:
        outputs = bsm_cached(workflow=workflow, concepts=concept_set, compact=True)
        if outputs is None:
            raise ValueError("Method returned None")

        story = workflow.tokenizer.decode(outputs['merge_tokens'][0])

        # extract the concept groups generated by the LLM
        group1_concepts = outputs['concept_groups'][0]
        group2_concepts = outputs['concept_groups'][1]

        # overall concept coverage
        concept_present = [concept.lower() in story.lower() for concept in concept_set]
        all_present = all(concept_present)
        coverage = sum(concept_present) / len(concept_set)

        # group-specific coverage
        group1_present = [concept.lower() in story.lower() for concept in group1_concepts]
        group1_coverage = sum(group1_present) / len(group1_concepts)

        group2_present = [concept.lower() in story.lower() for concept in group2_concepts]
        group2_coverage = sum(group2_present) / len(group2_concepts)

        cached_compact_stories.append(story)
        cached_compact_all_concepts.append(all_present)
        cached_compact_coverage.append(coverage)
        cached_compact_group1_coverage.append(group1_coverage)
        cached_compact_group2_coverage.append(group2_coverage)

    except Exception as e:
        print(f"Error in compact baseline: {e}")
        cached_compact_stories.append(f"ERROR: {str(e)}")
        cached_compact_all_concepts.append(False)
        cached_compact_coverage.append(0.0)
        cached_compact_group1_coverage.append(0.0)
        cached_compact_group2_coverage.append(0.0)

    if ((idx + 1) % 10) == 0:
        current = idx + 1

        baseline_all_pct = sum(baseline_all_concepts[:current]) / current * 100
        baseline_avg_pct = sum(baseline_coverage[:current]) / current * 100
        baseline_g1_pct = sum(baseline_group1_coverage[:current]) / current * 100
        baseline_g2_pct = sum(baseline_group2_coverage[:current]) / current * 100

        cached_all_pct = sum(cached_all_concepts[:current]) / current * 100
        cached_avg_pct = sum(cached_coverage[:current]) / current * 100
        cached_g1_pct = sum(cached_group1_coverage[:current]) / current * 100
        cached_g2_pct = sum(cached_group2_coverage[:current]) / current * 100

        cached_compact_all_pct = sum(cached_compact_all_concepts[:current]) / current * 100
        cached_compact_avg_pct = sum(cached_compact_coverage[:current]) / current * 100
        cached_compact_g1_pct = sum(cached_compact_group1_coverage[:current]) / current * 100
        cached_compact_g2_pct = sum(cached_compact_group2_coverage[:current]) / current * 100

        print(f"\n===== RESULTS ({current} samples) =====")
        print(f"BSM Baseline:         {baseline_all_pct:.2f}% all concepts, {baseline_avg_pct:.2f}% avg coverage")
        print(f"  Group 1: {baseline_g1_pct:.2f}%, Group 2: {baseline_g2_pct:.2f}%")

        print(f"BSM Cached:           {cached_all_pct:.2f}% all concepts, {cached_avg_pct:.2f}% avg coverage")
        print(f"  Group 1: {cached_g1_pct:.2f}%, Group 2: {cached_g2_pct:.2f}%")

        print(f"BSM Cached Compact:   {cached_compact_all_pct:.2f}% all concepts, {cached_compact_avg_pct:.2f}% avg coverage")
        print(f"  Group 1: {cached_compact_g1_pct:.2f}%, Group 2: {cached_compact_g2_pct:.2f}%")

total = len(concepts)

baseline_g1_std = np.std(baseline_group1_coverage) * 100
baseline_g2_std = np.std(baseline_group2_coverage) * 100
cached_g1_std = np.std(cached_group1_coverage) * 100
cached_g2_std = np.std(cached_group2_coverage) * 100
cached_compact_g1_std = np.std(cached_compact_group1_coverage) * 100
cached_compact_g2_std = np.std(cached_compact_group2_coverage) * 100

final_results = {
    'total_samples': total,
    'methods': {
        'bsm_baseline': {
            'all_concepts_pct': sum(baseline_all_concepts) / total * 100,
            'avg_coverage_pct': sum(baseline_coverage) / total * 100,
            'group1_coverage_pct': sum(baseline_group1_coverage) / total * 100,
            'group2_coverage_pct': sum(baseline_group2_coverage) / total * 100,
            'group1_coverage_std': baseline_g1_std,
            'group2_coverage_std': baseline_g2_std
        },
        'bsm_cached': {
            'all_concepts_pct': sum(cached_all_concepts) / total * 100,
            'avg_coverage_pct': sum(cached_coverage) / total * 100,
            'group1_coverage_pct': sum(cached_group1_coverage) / total * 100,
            'group2_coverage_pct': sum(cached_group2_coverage) / total * 100,
            'group1_coverage_std': cached_g1_std,
            'group2_coverage_std': cached_g2_std
        },
        'bsm_cached_compact': {
            'all_concepts_pct': sum(cached_compact_all_concepts) / total * 100,
            'avg_coverage_pct': sum(cached_compact_coverage) / total * 100,
            'group1_coverage_pct': sum(cached_compact_group1_coverage) / total * 100,
            'group2_coverage_pct': sum(cached_compact_group2_coverage) / total * 100,
            'group1_coverage_std': cached_compact_g1_std,
            'group2_coverage_std': cached_compact_g2_std
        }
    },
    'raw_data': {
        'concepts': concepts,
        'baseline': {
            'stories': baseline_stories,
            'all_concepts': baseline_all_concepts,
            'coverage': baseline_coverage,
            'group1_coverage': baseline_group1_coverage,
            'group2_coverage': baseline_group2_coverage
        },
        'cached': {
            'stories': cached_stories,
            'all_concepts': cached_all_concepts,
            'coverage': cached_coverage,
            'group1_coverage': cached_group1_coverage,
            'group2_coverage': cached_group2_coverage
        },
        'cached_compact': {
            'stories': cached_compact_stories,
            'all_concepts': cached_compact_all_concepts,
            'coverage': cached_compact_coverage,
            'group1_coverage': cached_compact_group1_coverage,
            'group2_coverage': cached_compact_group2_coverage
        }
    }
}

with open('/home/tbai4/llama3/dumps/bsm/llm_group_eval.json', 'w') as f:
    json.dump(final_results, f)

print("\n===== FINAL RESULTS =====")
for method in ['bsm_baseline', 'bsm_cached', 'bsm_cached_compact']:
    all_pct = final_results['methods'][method]['all_concepts_pct']
    avg_pct = final_results['methods'][method]['avg_coverage_pct']
    g1_pct = final_results['methods'][method]['group1_coverage_pct']
    g2_pct = final_results['methods'][method]['group2_coverage_pct']
    g1_std = final_results['methods'][method]['group1_coverage_std']
    g2_std = final_results['methods'][method]['group2_coverage_std']

    print(f"{method}: {all_pct:.2f}% all concepts, {avg_pct:.2f}% avg coverage")
    print(f"  Group 1: {g1_pct:.2f}% ± {g1_std:.2f}%")
    print(f"  Group 2: {g2_pct:.2f}% ± {g2_std:.2f}%")
