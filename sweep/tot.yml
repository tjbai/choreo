program: /home/tbai4/llama3/llama/workflows/finetune.py
command:
  - ${env}
  - "uv"
  - "run"
  - "python"
  - ${program}
  - "--task=tot"
  - "--data-path='/home/tbai4/llama3/dumps/tot/tot_data'"
  - "--ckpt-dir='/scratch4/jeisner1/tjbai/llama_8b'"
  - "--tokenizer-path='/scratch4/jeisner1/tjbai/llama_8b/tokenizer.model'"
  - ${args}

method: bayes
metric:
  name: val/correct
  goal: maximize
parameters:
  lora_rank:
    values: [16, 32, 64]
  lora_alpha:
    values: [8, 16, 32]
  lora_dropout:
    values: [0.05, 0.1, 0.2]
  learning_rate:
    distribution: log_uniform_values
    min: 1e-6
    max: 3e-4
  epochs:
    value: 2
  gradient_accumulation_steps:
    values: [4, 8, 16, 32]
  checkpoint_freq:
    value: 1e9 # don't checkpoint
  validation_freq:
    value: ${{int(1800 / int(${gradient_accumulation_steps}))}}
  max_seq_len:
    value: 8192

